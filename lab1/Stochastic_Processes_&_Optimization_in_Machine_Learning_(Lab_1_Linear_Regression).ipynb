{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCIo5COiZR65"
      },
      "source": [
        "<h1><b>The Linear Regression Algorithm</b></h1> <p align=\"justify\">In this exercise you will study the <i>linear regression</i> algorithm by developing your own Python program that implements all the necessary steps, without using any Python library that implements the <i>linear regression</i> model, such as <i>Scikit-Learn</i>.</p> <p align=\"justify\">Initially, two training data files are provided: (a) <i><a href=\"https://github.com/netmode/Stochastic-Processes-and-Optimization-in-Machine-Learning-Lab/blob/main/lab1/data1a.csv\">data1a.csv</a></i> and (b) <i><a href=\"https://github.com/netmode/Stochastic-Processes-and-Optimization-in-Machine-Learning-Lab/blob/main/lab1/data1b.csv\">data1b.csv</a></i>. Each row of the file <i>data1a.csv</i> includes information related to viewing a video on <i>YouTube</i>, such as <i>title</i>, <i>number of views</i>, <i>likes</i>, <i>dislikes</i>, etc. Overall, the file <i>data1a.csv</i> contains 11 columns. More information about the file <i>data1a.csv</i> can be found <a href=\"https://www.kaggle.com/akanshasingh/us-videos-csv\">here</a>. The file <i>data1b.csv</i> contains 2 columns with headers x and y respectively. These values do not have any physical meaning. More information can be found <a href=\"https://www.kaggle.com/testpython/linear-regression-with-single-variable\">here</a>.</p> <p align=\"justify\">The purpose of the exercise is to develop a simple <i>linear regression</i> model, which will be able to estimate (a) for the case of the file <i>data1a.csv</i> the number of <i>views</i> (dependent variable) of a video based on the number of <i>likes</i> (independent variable) it has received, and (b) for the case of the file <i>data1b.csv</i> the value of the variable y based on the values of the variable x. Develop a single program that does the following:</p> <ul> <li>It will load the data from the .csv files and isolate the columns that matter, i.e., in the case of the file data1a.csv the columns with headers views and likes, and in the case of the file data1b.csv the columns with headers y and x.</li> <li>It will compute the correlation between the independent and dependent variable of the provided data. This step is necessary to determine the degree of linear dependence between the two variables. What correlation results in the two cases? Is the linear dependence between the two variables satisfactory? For this question, study the source <a href=\"https://en.wikipedia.org/wiki/Correlation_and_dependence\">here</a>.</li> <li>It will plot the points that arise as pairs of the independent and dependent variable isolated in the first question. What do you observe in relation to the conclusions you reached in the second question?</li> <li>It will normalize the provided data using the min-max normalization method. More information about this method can be found <a href=\"https://en.wikipedia.org/wiki/Feature_scaling\">here</a>.</li> <li>It will randomly split the provided data into two subsets: (a) the training set, which includes the data that will be used to train the model, and (b) the test set, which includes the data that will be used to compute the modelâ€™s accuracy. The user will define the percentage of each file relative to the original.</li> <li>It will compute the parameters of the linear regression model using the Stochastic Gradient Descent (SGD) method. For this purpose, the user must define the learning rate and the total number of training epochs. Assume that the initial values of the parameters are zero.</li> <li>It will compute the mean squared error of the predictions on the test set. More information can be found <a href=\"https://en.wikipedia.org/wiki/Mean_squared_error\">here</a>.</li> </ul> <p align=\"justify\">Assume that the test set is 20% of the original dataset. What do you observe happens in the case where the data are not normalized? Experiment with the values of the learning rate and the number of epochs to see how the mean squared error changes.<p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mh1rOPC1eV1"
      },
      "source": [
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install pandas\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi6eokNdf30g"
      },
      "source": [
        "datas = pd.read_csv('data1a.csv')\n",
        "print(datas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii1-WiYOf8Uo"
      },
      "source": [
        "datas = pd.read_csv('data1b.csv')\n",
        "print(datas)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}